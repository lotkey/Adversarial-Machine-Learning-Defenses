{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Information\n",
        "The images were obtained from https://github.com/telecombcn-dl/2018-dlai-team4  \n",
        "This is a subset of the original LFW dataset, called \"optimized for accuracy\"  \n",
        "The subset is based only on celebrities with more than 20 images in LFW  \n",
        "A preprocessing step is applied to extract only the face from the whole images  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7THapbz9bPV"
      },
      "source": [
        "# Mounting Google Drive with Colab (optional)\n",
        "Also checks for a connected GPU. The connected GPU will not speed up this notebook and is not recommended because there are limits with using Colab GPUs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaavSZAb9a3A",
        "outputId": "9ec6988a-b900-4b23-cd7b-2330c9236aff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # mount drive\n",
        "\n",
        "# Check to see if using a GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') < 0:\n",
        "  print('Connected to a GPU.')\n",
        "  print('This project does not utilize a GPU, feel free to use a standard CPU runtime to avoid any GPU runtime limits.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFKDaYkEEbzo"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kt2cqS8J9UMG"
      },
      "outputs": [],
      "source": [
        "from os import listdir  # for loading all images in the dataset\n",
        "\n",
        "from PIL import Image   # For loading images\n",
        "import numpy as np      # Numpy arrays, more memory-efficient than Python lists, useful built-in array functions (min/max of multidimensional array, normalization)\n",
        "import pandas as pd     # For loading CSVs\n",
        "import pickle           # For exporting data\n",
        "import natsort          # For sorting filenames\n",
        "from tensorflow.keras.utils import to_categorical   # Converting array of integers into array of one-hot vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v25Dr0E_E2Vg"
      },
      "source": [
        "# Setting paths/directories/variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KyaCgxc-oZ0"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = 'drive/My Drive/Colab Notebooks/LFW/'  # Raw dataset, contains CSVs and subdirectories for train/test/val\n",
        "TEST_DIR = DATA_DIR + 'Test/'                     # Test subdirectory                  \n",
        "TRAIN_DIR = DATA_DIR + 'Train/'                   # Train subdirectory\n",
        "VAL_DIR = DATA_DIR + 'Validation/'                # Validation subdirectory\n",
        "\n",
        "NAME_LIST_PATH = DATA_DIR + 'name_list.csv'       # List of all classes\n",
        "PICKLED_DATA_PATH = 'drive/My Drive/Colab Notebooks/data.pickled'   # Output path for processed dataset\n",
        "\n",
        "IMG_SHAPE = (100, 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bmzG4CbE5TD"
      },
      "source": [
        "# Getting the number of classes\n",
        "Used for converting from names to one-hot vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnWYLDO6ApEZ",
        "outputId": "2c806068-3d40-439a-f8c0-ea2537f4358e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 'Gloria_Macapagal_Arroyo']\n",
            " [1 'Jennifer_Capriati']\n",
            " [2 'Laura_Bush']\n",
            " [3 'Winona_Ryder']\n",
            " [4 'Tiger_Woods']\n",
            " [5 'Hugo_Chavez']\n",
            " [6 'John_Negroponte']\n",
            " [7 'George_W_Bush']\n",
            " [8 'Roh_Moo-hyun']\n",
            " [9 'Paul_Bremer']\n",
            " [10 'George_Robertson']\n",
            " [11 'Tom_Daschle']\n",
            " [12 'Ricardo_Lagos']\n",
            " [13 'Jennifer_Lopez']\n",
            " [14 'Jose_Maria_Aznar']\n",
            " [15 'Silvio_Berlusconi']\n",
            " [16 'Vicente_Fox']\n",
            " [17 'Jennifer_Aniston']\n",
            " [18 'Gerhard_Schroeder']\n",
            " [19 'David_Beckham']\n",
            " [20 'Kofi_Annan']\n",
            " [21 'Igor_Ivanov']\n",
            " [22 'Jiang_Zemin']\n",
            " [23 'Mahmoud_Abbas']\n",
            " [24 'Pete_Sampras']\n",
            " [25 'Guillermo_Coria']\n",
            " [26 'Donald_Rumsfeld']\n",
            " [27 'Megawati_Sukarnoputri']\n",
            " [28 'Jeremy_Greenstock']\n",
            " [29 'Junichiro_Koizumi']\n",
            " [30 'Jack_Straw']\n",
            " [31 'Rudolph_Giuliani']\n",
            " [32 'Jacques_Chirac']\n",
            " [33 'Saddam_Hussein']\n",
            " [34 'John_Ashcroft']\n",
            " [35 'Lindsay_Davenport']\n",
            " [36 'Naomi_Watts']\n",
            " [37 'Lleyton_Hewitt']\n",
            " [38 'Hamid_Karzai']\n",
            " [39 'Tom_Ridge']\n",
            " [40 'Recep_Tayyip_Erdogan']\n",
            " [41 'Tony_Blair']\n",
            " [42 'Hans_Blix']\n",
            " [43 'Jean_Chretien']\n",
            " [44 'Nestor_Kirchner']\n",
            " [45 'Gray_Davis']\n",
            " [46 'Michael_Bloomberg']\n",
            " [47 'Luiz_Inacio_Lula_da_Silva']\n",
            " [48 'Juan_Carlos_Ferrero']\n",
            " [49 'Vladimir_Putin']\n",
            " [50 'Serena_Williams']\n",
            " [51 'Alejandro_Toledo']\n",
            " [52 'Alvaro_Uribe']\n",
            " [53 'Amelie_Mauresmo']\n",
            " [54 'Andre_Agassi']\n",
            " [55 'Angelina_Jolie']\n",
            " [56 'Ariel_Sharon']\n",
            " [57 'Arnold_Schwarzenegger']\n",
            " [58 'Atal_Bihari_Vajpayee']\n",
            " [59 'Bill_Clinton']\n",
            " [60 'Carlos_Menem']\n",
            " [61 'Colin_Powell']]\n",
            "Number of classes: 62\n"
          ]
        }
      ],
      "source": [
        "name_list = pd.read_csv(NAME_LIST_PATH).values\n",
        "print(name_list)\n",
        "NUM_CLASSES = len(name_list)  # Number of classes is the number of names in the list\n",
        "\n",
        "print(f'Number of classes: {NUM_CLASSES}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMB40x0XVr7l"
      },
      "source": [
        "# Loading images\n",
        "And normalizing them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyiF1YKpCiBs"
      },
      "outputs": [],
      "source": [
        "imgs = [[], [], []] # Empty list of empty lists, imgs[0] = test images, imgs[1] = train images, imgs[2] = validation images\n",
        "paths = [TEST_DIR, TRAIN_DIR, VAL_DIR]  # Create a list of paths to loop through\n",
        "\n",
        "for i, path in enumerate(paths):                # Loop through each path with index i\n",
        "  filenames = natsort.natsorted(listdir(path))\n",
        "  for filename in filenames:                # Loop through all files in the path\n",
        "    with Image.open(path + filename) as image:  # Open the image at path + filename with PIL Image library\n",
        "      imgs[i].append(np.asarray(image.resize(IMG_SHAPE)))         # Convert to a numpy array and append to the corresponding list in imgs\n",
        "\n",
        "for i in range(len(imgs)):        # Loop through each list\n",
        "  imgs[i] = np.asarray(imgs[i])   # Convert to a numpy array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKMSHX070jP1"
      },
      "source": [
        "## Normalizing images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bkB8hpf0ep3",
        "outputId": "96b1ea75-414e-4387-9c5a-a2d192471c4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test images\n",
            "Min: 0\n",
            "Max: 255\n",
            "Average: 121.01817683508104\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalized test images:\n",
            "Min: 0.0\n",
            "Max: 1.0\n",
            "Average: 0.4745810856277703\n"
          ]
        }
      ],
      "source": [
        "# Find the maximum value in the test images\n",
        "max_imgs = np.argmax(imgs[0]) # Unravels imgs[0] to a single-dimensional array and returns the index of the largest element\n",
        "max_imgs = np.unravel_index(max_imgs, imgs[0].shape)  # Converts index for unraveled array into multi-dimensional index\n",
        "max_imgs = imgs[0][max_imgs]  # Index imgs[0] with the multi-dimensional index\n",
        "\n",
        "# Repeat, but find minimum instead of maximum\n",
        "min_imgs = np.argmin(imgs[0])\n",
        "min_imgs = np.unravel_index(min_imgs, imgs[0].shape)\n",
        "min_imgs = imgs[0][min_imgs]\n",
        "\n",
        "print(f'Test images')\n",
        "print(f'Min: {min_imgs}')\n",
        "print(f'Max: {max_imgs}')\n",
        "print(f'Average: {np.average(imgs[0])}\\n')\n",
        "\n",
        "# Images are represented as multi-dimensional arrays with values in the range [0-255]\n",
        "# 2 dimensions for black-and-white images, 3 dimensions for RGB images, 4 dimensions for RGBA images\n",
        "# Simplest way to normalize images is to divide all values by 255 to get an array with floats in the range [0.0-1.0]\n",
        "# Normalizing input can make training a neural network much faster\n",
        "# Especially helpful if a network takes inputs that have different ranges (image array with values [0-255], age [0-~120])\n",
        "imgs = np.asarray(imgs) / 255.0   # Normalize the images to values between 0.0 and 1.0 (inclusive)\n",
        "\n",
        "# Find the max and min again\n",
        "max_imgs = np.argmax(imgs[0])\n",
        "max_imgs = np.unravel_index(max_imgs, imgs[0].shape)\n",
        "max_imgs = imgs[0][max_imgs]\n",
        "\n",
        "min_imgs = np.argmin(imgs[0])\n",
        "min_imgs = np.unravel_index(min_imgs, imgs[0].shape)\n",
        "min_imgs = imgs[0][min_imgs]\n",
        "\n",
        "print(f'Normalized test images:')\n",
        "print(f'Min: {min_imgs}')\n",
        "print(f'Max: {max_imgs}')\n",
        "print(f'Average: {np.average(imgs[0])}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_spbYN0fyHJ"
      },
      "source": [
        "# Loading labels\n",
        "And converting them to one-hot vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmUOL7vOV43g",
        "outputId": "3b16f617-f440-4e49-9148-1fd5efef125f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training labels shape: (3043, 1)\n",
            "Training labels one-hot shape: (3043, 62)\n"
          ]
        }
      ],
      "source": [
        "# The labels for each set (train, test, validate) are stored as a list of integers  \n",
        "# There is a CSV that maps each integer to a string name (should be at NAME_LIST_PATH)  \n",
        "# One-hot vectors is kind of like a way of normalizing categorical data (colors, names, street names, gender, etc.)  \n",
        "# If there are two classes: red and blue  \n",
        "#   I can assign 1 to red and 2 to blue (arbitrary)  \n",
        "# Then if my test labels are this list: [1, 2, 1, 1]  \n",
        "#   They will be converted into this list of one-hot vectors: [[1, 0], [0, 1], [1, 0], [1, 0]]  \n",
        "#     where each one-hot vector is a Boolean vector (0 = false, 1 = true): [is red, is blue]\n",
        "# Whole set becomes a Boolean matrix where the row is the image index and the column is the categorical index\n",
        "\n",
        "# Load the CSVs as an array of integers\n",
        "test_labels = pd.read_csv(f'{DATA_DIR}test_labels.csv', header=None).values.astype(np.uint)\n",
        "train_labels = pd.read_csv(f'{DATA_DIR}train_labels.csv', header=None).values.astype(np.uint)\n",
        "val_labels = pd.read_csv(f'{DATA_DIR}val_labels.csv', header=None).values.astype(np.uint)\n",
        "\n",
        "# Convert the array of integers to an array of one-hot encoded vectors\n",
        "test_labels_onehot = to_categorical(test_labels, num_classes=NUM_CLASSES)\n",
        "train_labels_onehot = to_categorical(train_labels, num_classes=NUM_CLASSES)\n",
        "val_labels_onehot = to_categorical(val_labels, num_classes=NUM_CLASSES)\n",
        "\n",
        "print(f'Training labels shape: {train_labels.shape}')                 # (number of training images x 1), list of single integers\n",
        "print(f'Training labels one-hot shape: {train_labels_onehot.shape}')  # (number of training images x number of classes), list of one-hot vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuW7wAe2Axn5"
      },
      "source": [
        "# Printing shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "No7imF93A0Dq",
        "outputId": "a19dd6ff-ddee-42de-f760-a2d566407306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing data shapes\n",
            "X: (1049, 100, 100, 3)\n",
            "y: (1049, 62)\n",
            "\n",
            "Training data shapes\n",
            "X: (3043, 100, 100, 3)\n",
            "y: (3043, 62)\n",
            "\n",
            "Validation data shapes\n",
            "X: (1021, 100, 100, 3)\n",
            "y: (1021, 62)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Testing data shapes')\n",
        "print(f'X: {imgs[0].shape}')\n",
        "print(f'y: {test_labels_onehot.shape}\\n')\n",
        "\n",
        "print('Training data shapes')\n",
        "print(f'X: {imgs[1].shape}')\n",
        "print(f'y: {train_labels_onehot.shape}\\n')\n",
        "\n",
        "print('Validation data shapes')\n",
        "print(f'X: {imgs[2].shape}')\n",
        "print(f'y: {val_labels_onehot.shape}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL62YjFEfzlg"
      },
      "source": [
        "# Exporting data as a pickled object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9YQM4IMaV_4"
      },
      "outputs": [],
      "source": [
        "with open(PICKLED_DATA_PATH, 'wb') as outfile:  # Open output file\n",
        "  pickle.dump((imgs[1], train_labels_onehot, imgs[0], test_labels_onehot, imgs[2], val_labels_onehot), outfile)                    # Save data tuple as a pickled object"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "J7THapbz9bPV",
        "PFKDaYkEEbzo",
        "v25Dr0E_E2Vg",
        "4bmzG4CbE5TD",
        "u_spbYN0fyHJ",
        "sL62YjFEfzlg"
      ],
      "name": "data_loader.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
